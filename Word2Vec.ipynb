{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import sklearn\n",
    "import spacy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import gutenberg, stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to clean text.\n",
    "def text_cleaner(text):\n",
    "    \n",
    "    # Visual inspection shows spaCy does not recognize the double dash '--'.\n",
    "    # Better get rid of it now!\n",
    "    text = re.sub(r'--',' ',text)\n",
    "    \n",
    "    # Get rid of headings in square brackets.\n",
    "    text = re.sub(\"[\\[].*?[\\]]\", \"\", text)\n",
    "    \n",
    "    # Get rid of chapter titles.\n",
    "    text = re.sub(r'Chapter \\d+','',text)\n",
    "    \n",
    "    # Get rid of extra whitespace.\n",
    "    text = ' '.join(text.split())\n",
    "    \n",
    "    return text\n",
    "\n",
    "\n",
    "# Import all the Austen in the Project Gutenberg corpus.\n",
    "austen = ''\n",
    "for novel in ['persuasion','emma','sense']:\n",
    "    work = gutenberg.raw('austen-' + novel + '.txt')\n",
    "    austen = austen + work\n",
    "    \n",
    "chesterton=''\n",
    "for novel in ['chesterton-ball.txt', 'chesterton-brown.txt', 'chesterton-thursday.txt']:\n",
    "    work = gutenberg.raw(novel)\n",
    "    chesterton += work\n",
    "\n",
    "# Clean the data.\n",
    "austen_clean = text_cleaner(austen[:1000000])\n",
    "chesterton_clean = text_cleaner(chesterton[:1000000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the data. This can take some time.\n",
    "nlp = spacy.load('en')\n",
    "austen_doc = nlp(austen_clean)\n",
    "chesterton_doc=nlp(chesterton_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['for', 'daughter', 'eld', 'give', 'thing', 'tempt']\n",
      "Austen has 8817 sentences and 990979 tokens.\n",
      "Chesterton has 9835 sentences and 984704 tokens.\n"
     ]
    }
   ],
   "source": [
    "# Organize the parsed doc into sentences, while filtering out punctuation\n",
    "# and stop words, and converting words to lower case lemmas.\n",
    "\n",
    "def doc2sentences(nlpdoc):\n",
    "    sentences = []\n",
    "    for sentence in nlpdoc.sents:\n",
    "        sentence = [\n",
    "            token.lemma_.lower()\n",
    "            for token in sentence\n",
    "            if not token.is_stop\n",
    "            and not token.is_punct\n",
    "        ]\n",
    "        sentences.append(sentence)\n",
    "    return sentences\n",
    "\n",
    "sentences = doc2sentences(austen_doc)\n",
    "chesterton_sentences = doc2sentences(chesterton_doc)\n",
    "\n",
    "\n",
    "print(sentences[20])\n",
    "print('Austen has {} sentences and {} tokens.'.format(len(sentences), len(austen_clean)))\n",
    "print('Chesterton has {} sentences and {} tokens.'.format(len(chesterton_sentences), len(chesterton_clean)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done!\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action='ignore', category=UserWarning, module='gensim')\n",
    "import gensim\n",
    "from gensim.models import word2vec\n",
    "\n",
    "vec_dim = 300\n",
    "model = word2vec.Word2Vec(\n",
    "    sentences + chesterton_sentences,\n",
    "    workers=4,     # Number of threads to run in parallel (if your computer does parallel processing).\n",
    "    min_count=5,   # Minimum word count threshold.\n",
    "    window=5,      # Number of words around target word to consider.\n",
    "    sg=0,          # Use CBOW because our corpus is small.\n",
    "    sample=1e-3 ,  # Penalize frequent words.\n",
    "    size=vec_dim,      # Word vector length.\n",
    "    iter=6,\n",
    "    hs=1           # Use hierarchical softmax.\n",
    ")\n",
    "\n",
    "print('done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('sherry', 0.7841025590896606), ('fallen', 0.7547245025634766), ('claude', 0.7529209852218628), ('wilson', 0.7263314127922058), ('seymour', 0.7219710946083069), ('walter', 0.7112399935722351), ('cowdray', 0.7021132707595825), ('reality', 0.6875311136245728), ('foam', 0.6855844259262085), ('anne', 0.6803672313690186)]\n",
      "0.8873249348855472\n",
      "0.6576083311205722\n",
      "large\n"
     ]
    }
   ],
   "source": [
    "# List of words in model.\n",
    "vocab = model.wv.vocab.keys()\n",
    "\n",
    "print(model.wv.most_similar(positive=['mr', 'man'], negative=['woman']))\n",
    "\n",
    "# Similarity is calculated using the cosine, so again 1 is total\n",
    "# similarity and 0 is no similarity.\n",
    "print(model.wv.similarity('loud', 'aloud'))\n",
    "print(model.wv.similarity('mr', 'mrs'))\n",
    "\n",
    "\n",
    "# One of these things is not like the other...\n",
    "print(model.wv.doesnt_match(\"breakfast large dinner lunch\".split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence2vec(sentence):\n",
    "    if any(word in sentence for word in vocab):\n",
    "        return np.mean([model.wv.word_vec(word) for word in sentence if word in vocab], axis=0)\n",
    "    else:\n",
    "        return np.zeros(vec_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>author</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[sir, walter, elliot, kellynch, hall, somerset...</td>\n",
       "      <td>austen</td>\n",
       "      <td>0.151300</td>\n",
       "      <td>0.054095</td>\n",
       "      <td>-0.195630</td>\n",
       "      <td>0.066961</td>\n",
       "      <td>0.073186</td>\n",
       "      <td>0.024032</td>\n",
       "      <td>-0.215450</td>\n",
       "      <td>-0.157420</td>\n",
       "      <td>...</td>\n",
       "      <td>0.156527</td>\n",
       "      <td>-0.037100</td>\n",
       "      <td>-0.037329</td>\n",
       "      <td>-0.137503</td>\n",
       "      <td>0.181644</td>\n",
       "      <td>0.235000</td>\n",
       "      <td>0.110988</td>\n",
       "      <td>0.086285</td>\n",
       "      <td>-0.096540</td>\n",
       "      <td>-0.112739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[this, page, favourite, volume, open, elliot, ...</td>\n",
       "      <td>austen</td>\n",
       "      <td>0.184816</td>\n",
       "      <td>0.073297</td>\n",
       "      <td>-0.194881</td>\n",
       "      <td>0.035354</td>\n",
       "      <td>0.079643</td>\n",
       "      <td>0.041703</td>\n",
       "      <td>-0.207674</td>\n",
       "      <td>-0.067473</td>\n",
       "      <td>...</td>\n",
       "      <td>0.205798</td>\n",
       "      <td>-0.167607</td>\n",
       "      <td>-0.073210</td>\n",
       "      <td>-0.111982</td>\n",
       "      <td>0.182613</td>\n",
       "      <td>0.232798</td>\n",
       "      <td>0.091440</td>\n",
       "      <td>0.137984</td>\n",
       "      <td>-0.126915</td>\n",
       "      <td>-0.145583</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 302 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  author         0  \\\n",
       "0  [sir, walter, elliot, kellynch, hall, somerset...  austen  0.151300   \n",
       "1  [this, page, favourite, volume, open, elliot, ...  austen  0.184816   \n",
       "\n",
       "          1         2         3         4         5         6         7  \\\n",
       "0  0.054095 -0.195630  0.066961  0.073186  0.024032 -0.215450 -0.157420   \n",
       "1  0.073297 -0.194881  0.035354  0.079643  0.041703 -0.207674 -0.067473   \n",
       "\n",
       "     ...          290       291       292       293       294       295  \\\n",
       "0    ...     0.156527 -0.037100 -0.037329 -0.137503  0.181644  0.235000   \n",
       "1    ...     0.205798 -0.167607 -0.073210 -0.111982  0.182613  0.232798   \n",
       "\n",
       "        296       297       298       299  \n",
       "0  0.110988  0.086285 -0.096540 -0.112739  \n",
       "1  0.091440  0.137984 -0.126915 -0.145583  \n",
       "\n",
       "[2 rows x 302 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group into sentences.\n",
    "austen_rows = [[sent, 'austen'] for sent in sentences]\n",
    "chesterton_rows = [[sent, 'chesterton'] for sent in chesterton_sentences]\n",
    "\n",
    "#create dataframe for SVC\n",
    "df = pd.DataFrame(austen_rows + chesterton_rows, columns=['sentence', 'author'])\n",
    "\n",
    "#list of vectors to concat to data frame\n",
    "vectors = []\n",
    "for sentence in df.sentence:\n",
    "    vectors.append(sentence2vec(sentence))\n",
    "\n",
    "df2 = pd.DataFrame(vectors)\n",
    "\n",
    "#concat setnences/author to vector dataframe\n",
    "df = pd.concat([df, df2], axis=1)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['author', 'sentence'], axis=1)\n",
    "y = df.author\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8415492957746479\n",
      "0.8378817413905133\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "svc = LinearSVC(C=29, random_state=42)\n",
    "svc.fit(X_train, y_train)\n",
    "\n",
    "print(svc.score(X_train, y_train))\n",
    "print(svc.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.854433418693982\n",
      "0.8476283300844705\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(C=2500, random_state=42)\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "print(lr.score(X_train, y_train))\n",
    "print(lr.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "chesterton    3246\n",
       "austen        2910\n",
       "Name: author, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "96px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
