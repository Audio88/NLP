{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import sklearn\n",
    "import spacy\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unsupervised Learning Capstone\n",
    "\n",
    "Word2vec soloution, much slower and not as accurate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>song</th>\n",
       "      <th>year</th>\n",
       "      <th>artist</th>\n",
       "      <th>genre</th>\n",
       "      <th>lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>ego-remix</td>\n",
       "      <td>2009</td>\n",
       "      <td>beyonce-knowles</td>\n",
       "      <td>Pop</td>\n",
       "      <td>Oh baby, how you doing?\\nYou know I'm gonna cu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>then-tell-me</td>\n",
       "      <td>2009</td>\n",
       "      <td>beyonce-knowles</td>\n",
       "      <td>Pop</td>\n",
       "      <td>playin' everything so easy,\\nit's like you see...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>honesty</td>\n",
       "      <td>2009</td>\n",
       "      <td>beyonce-knowles</td>\n",
       "      <td>Pop</td>\n",
       "      <td>If you search\\nFor tenderness\\nIt isn't hard t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>you-are-my-rock</td>\n",
       "      <td>2009</td>\n",
       "      <td>beyonce-knowles</td>\n",
       "      <td>Pop</td>\n",
       "      <td>Oh oh oh I, oh oh oh I\\n[Verse 1:]\\nIf I wrote...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>black-culture</td>\n",
       "      <td>2009</td>\n",
       "      <td>beyonce-knowles</td>\n",
       "      <td>Pop</td>\n",
       "      <td>Party the people, the people the party it's po...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index             song  year           artist genre  \\\n",
       "0      0        ego-remix  2009  beyonce-knowles   Pop   \n",
       "1      1     then-tell-me  2009  beyonce-knowles   Pop   \n",
       "2      2          honesty  2009  beyonce-knowles   Pop   \n",
       "3      3  you-are-my-rock  2009  beyonce-knowles   Pop   \n",
       "4      4    black-culture  2009  beyonce-knowles   Pop   \n",
       "\n",
       "                                              lyrics  \n",
       "0  Oh baby, how you doing?\\nYou know I'm gonna cu...  \n",
       "1  playin' everything so easy,\\nit's like you see...  \n",
       "2  If you search\\nFor tenderness\\nIt isn't hard t...  \n",
       "3  Oh oh oh I, oh oh oh I\\n[Verse 1:]\\nIf I wrote...  \n",
       "4  Party the people, the people the party it's po...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('lyrics.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(362237, 6)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index         0\n",
       "song          2\n",
       "year          0\n",
       "artist        0\n",
       "genre         0\n",
       "lyrics    95680\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 5)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Cleaning text, This should catch everything that spacys neural networks don't.\n",
    "def text_cleaner(text):\n",
    "    text = re.sub(r'--',' ',text)\n",
    "    # Get rid of headings in square brackets.\n",
    "    text = re.sub(\"[\\[].*?[\\]]\", \"\", text)\n",
    "    # Get rid of \\n.\n",
    "    text = re.sub(r\"\\n\", \" \", text)\n",
    "    # Get rid of extra whitespace.\n",
    "    text = ' '.join(text.split())\n",
    "    return text\n",
    "\n",
    "df.dropna(inplace=True)\n",
    "df.lyrics = df.lyrics.apply(text_cleaner)\n",
    "\n",
    "#Droping all rows with null values, the 10,000 rows with out lyrics can't be used\n",
    "#and the two rows with out song ids won't be missed\n",
    "#Also droping rows where lyrics were missing, but not NAN, and Rows where genre is not available/other\n",
    "df.dropna(inplace=True)\n",
    "df.drop((df[df.genre == 'Not Available'].index),inplace=True, axis=0)\n",
    "df.drop((df[df.genre == 'Other'].index),inplace=True, axis=0)\n",
    "df.drop((df[df.lyrics.str.len() < 1].index), inplace=True, axis=0)\n",
    "\n",
    "#for now reducing data set to 10,000 to save time\n",
    "df = df.sample(10000, random_state=42)\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "df.drop('index', inplace=True, axis=1)\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "en       9158\n",
      "es        244\n",
      "de        119\n",
      "ro         73\n",
      "id         64\n",
      "fr         59\n",
      "it         46\n",
      "pt         39\n",
      "sw         35\n",
      "error      24\n",
      "nl         20\n",
      "fi         16\n",
      "tr         14\n",
      "tl         14\n",
      "sv         12\n",
      "no         10\n",
      "hu          8\n",
      "pl          7\n",
      "da          6\n",
      "ca          6\n",
      "af          5\n",
      "so          5\n",
      "lt          4\n",
      "sq          4\n",
      "cy          3\n",
      "hr          3\n",
      "lv          1\n",
      "vi          1\n",
      "Name: language, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(9158, 5)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Language detection was out of the scope of this project so we're just doing a quick and dirty clean up\n",
    "#with pythons' langdetect package. Droping all rows where language was not english.\n",
    "from langdetect import detect\n",
    "\n",
    "def detect_try(text):\n",
    "    try:\n",
    "        return detect(text)\n",
    "    except:\n",
    "        return 'error'\n",
    "\n",
    "#Language column\n",
    "df['language'] = df.lyrics.apply(detect_try)\n",
    "print(df.language.value_counts())\n",
    "\n",
    "#droping language column and rows that aren't english\n",
    "df.drop((df[df.language != 'en'].index), inplace=True, axis=0)\n",
    "df.drop('language', inplace=True, axis=1)\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    Slaves to the power of sin Once in captivity to darkness; spiritually dead A voice cried from the top of a hill \"It is finished\"! It awakened those who were once dead But now we live For us Now we live a new life in freedom Not being enslaved by the power of any Jesus' blood has made us free But the battle still remains We contend not with flesh and blood But with spiritual darkness For this we wage war But not against man This war is with darkness And not against flesh and blood The Holy Bo...\n",
       "2    You better be nice, you better think twice, you better be careful You better be nice, you better think twice, you better be careful Are you dreaming, I can see it in your eyes Something tells me, you're about to say goodbye And I wonder, are you tired of my touch Once you held me now it doesn't mean as much You don't love me like you used to love me baby Body, soul and mind, hey hey hey Before you go, throw it all away, take some advice You better be nice, you better think twice, you better ...\n",
       "Name: lyrics, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', 500)\n",
    "df.lyrics.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    [[slave, to, the, power, of, sin, once, in, captivity, to, darkness, spiritually, dead, a, voice, cry, from, the, top, of, a, hill], [It, be, finish], [It, awaken, those, who, be, once, dead], [but, now, we, live, for, us], [now, we, live, a, new, life, in, freedom, not, be, enslave, by, the, power, of, any, jesus, blood], [have, make, us, free], [but, the, battle, still, remain], [We, contend, not, with, flesh, and, blood, but, with, spiritual, darkness, for, this, we, wage, war, but, not, ...\n",
       "2    [[You, better, be, nice, you, better, think, twice, you, better, be, careful, You, better, be, nice, you, better, think, twice, you, better, be, careful, be, you, dream, I, can, see, it, in, -PRON-, eye], [something, tell, me, you, be, about, to, say, goodbye], [and, I, wonder, be, you, tired, of, -PRON-, touch], [once, you, hold, me, now, it, do, not, mean, as, much, You, do, not, love, me, like, you, use, to, love, me, baby, body, soul, and, mind], [hey, hey], [hey, before, you, go, throw,...\n",
       "Name: Lemmatized_sentences, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#removing chained assignment warning\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "#Getting Lemmas from our Spacy Docs\n",
    "def doc2sentences(nlpdoc):\n",
    "    sentences = []\n",
    "    for sentence in nlpdoc.sents:\n",
    "        lemmas = []\n",
    "        for token in sentence:\n",
    "            if token.pos_ == 'PRON':\n",
    "                lemmas.append(token.text)\n",
    "            elif token.is_punct:\n",
    "                pass\n",
    "            else:\n",
    "                lemmas.append(token.lemma_)\n",
    "        sentences.append(lemmas)\n",
    "    return sentences\n",
    "\n",
    "\n",
    "#Loading the spacy english model\n",
    "#Using Spacy to parse lyrics and create docs\n",
    "#This spacy model has 1.1 million word vectors that will help us generate our doc vectors.\n",
    "nlp = spacy.load('en')\n",
    "docs = [] \n",
    "sents = []\n",
    "\n",
    "#Spacy pipeline docs\n",
    "for doc in nlp.pipe(iter(df['lyrics']),batch_size=256):\n",
    "    docs.append(doc)\n",
    "    sents.append(doc2sentences(doc))\n",
    "    \n",
    "df['Lemmatized_sentences'] = sents\n",
    "df.Lemmatized_sentences.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action='ignore', category=UserWarning, module='gensim')\n",
    "import gensim\n",
    "from gensim.models import word2vec\n",
    "\n",
    "\n",
    "#This creates sentence vectors out of word2vec vectors and then creates doc vectors out of setnences\n",
    "def document2vec(doc, vec_dim):\n",
    "    sentence_vectors = []\n",
    "    for sent in doc:\n",
    "        #check if our sentence has any words in the google news vocab, if not return empty vector with zeros\n",
    "        if any(word in sent for word in vocab):\n",
    "            #For each word in our sentence return a word2vec vector to create a list of vectors\n",
    "            #Then average the vectors together.\n",
    "            vec = np.mean([model.word_vec(word) for word in sent if word in vocab], axis=0)\n",
    "            sentence_vectors.append(vec)\n",
    "        else:\n",
    "            vec = np.zeros(vec_dim)\n",
    "            sentence_vectors.append(vec)\n",
    "    return np.mean(sentence_vectors, axis=0)\n",
    "\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format ('GoogleNews-vectors-negative300.bin', binary=True)\n",
    "\n",
    "# List of words in model.\n",
    "vocab = model.vocab.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>song</th>\n",
       "      <th>year</th>\n",
       "      <th>artist</th>\n",
       "      <th>genre</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>Lemmatized_sentences</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>...</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>flesh-and-blood</td>\n",
       "      <td>2007</td>\n",
       "      <td>deliverance</td>\n",
       "      <td>Metal</td>\n",
       "      <td>Slaves to the power of sin Once in captivity to darkness; spiritually dead A voice cried from the top of a hill \"It is finished\"! It awakened those who were once dead But now we live For us Now we live a new life in freedom Not being enslaved by the power of any Jesus' blood has made us free But the battle still remains We contend not with flesh and blood But with spiritual darkness For this we wage war But not against man This war is with darkness And not against flesh and blood The Holy Bo...</td>\n",
       "      <td>[[slave, to, the, power, of, sin, once, in, captivity, to, darkness, spiritually, dead, a, voice, cry, from, the, top, of, a, hill], [It, be, finish], [It, awaken, those, who, be, once, dead], [but, now, we, live, for, us], [now, we, live, a, new, life, in, freedom, not, be, enslave, by, the, power, of, any, jesus, blood], [have, make, us, free], [but, the, battle, still, remain], [We, contend, not, with, flesh, and, blood, but, with, spiritual, darkness, for, this, we, wage, war, but, not, ...</td>\n",
       "      <td>0.018069</td>\n",
       "      <td>0.056996</td>\n",
       "      <td>0.053011</td>\n",
       "      <td>0.082020</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.078472</td>\n",
       "      <td>0.024860</td>\n",
       "      <td>-0.092086</td>\n",
       "      <td>0.004420</td>\n",
       "      <td>-0.039378</td>\n",
       "      <td>-0.002943</td>\n",
       "      <td>-0.012103</td>\n",
       "      <td>-0.049402</td>\n",
       "      <td>0.062549</td>\n",
       "      <td>-0.053977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>be-careful</td>\n",
       "      <td>2007</td>\n",
       "      <td>dannii-minogue</td>\n",
       "      <td>Pop</td>\n",
       "      <td>You better be nice, you better think twice, you better be careful You better be nice, you better think twice, you better be careful Are you dreaming, I can see it in your eyes Something tells me, you're about to say goodbye And I wonder, are you tired of my touch Once you held me now it doesn't mean as much You don't love me like you used to love me baby Body, soul and mind, hey hey hey Before you go, throw it all away, take some advice You better be nice, you better think twice, you better ...</td>\n",
       "      <td>[[You, better, be, nice, you, better, think, twice, you, better, be, careful, You, better, be, nice, you, better, think, twice, you, better, be, careful, be, you, dream, I, can, see, it, in, -PRON-, eye], [something, tell, me, you, be, about, to, say, goodbye], [and, I, wonder, be, you, tired, of, -PRON-, touch], [once, you, hold, me, now, it, do, not, mean, as, much, You, do, not, love, me, like, you, use, to, love, me, baby, body, soul, and, mind], [hey, hey], [hey, before, you, go, throw,...</td>\n",
       "      <td>-0.000483</td>\n",
       "      <td>0.010578</td>\n",
       "      <td>0.104912</td>\n",
       "      <td>0.130242</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019077</td>\n",
       "      <td>0.165598</td>\n",
       "      <td>-0.149622</td>\n",
       "      <td>0.030454</td>\n",
       "      <td>-0.003322</td>\n",
       "      <td>-0.068253</td>\n",
       "      <td>0.024765</td>\n",
       "      <td>-0.087031</td>\n",
       "      <td>-0.027532</td>\n",
       "      <td>-0.014364</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 306 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              song  year          artist  genre  \\\n",
       "0  flesh-and-blood  2007     deliverance  Metal   \n",
       "1       be-careful  2007  dannii-minogue    Pop   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                lyrics  \\\n",
       "0  Slaves to the power of sin Once in captivity to darkness; spiritually dead A voice cried from the top of a hill \"It is finished\"! It awakened those who were once dead But now we live For us Now we live a new life in freedom Not being enslaved by the power of any Jesus' blood has made us free But the battle still remains We contend not with flesh and blood But with spiritual darkness For this we wage war But not against man This war is with darkness And not against flesh and blood The Holy Bo...   \n",
       "1  You better be nice, you better think twice, you better be careful You better be nice, you better think twice, you better be careful Are you dreaming, I can see it in your eyes Something tells me, you're about to say goodbye And I wonder, are you tired of my touch Once you held me now it doesn't mean as much You don't love me like you used to love me baby Body, soul and mind, hey hey hey Before you go, throw it all away, take some advice You better be nice, you better think twice, you better ...   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  Lemmatized_sentences  \\\n",
       "0  [[slave, to, the, power, of, sin, once, in, captivity, to, darkness, spiritually, dead, a, voice, cry, from, the, top, of, a, hill], [It, be, finish], [It, awaken, those, who, be, once, dead], [but, now, we, live, for, us], [now, we, live, a, new, life, in, freedom, not, be, enslave, by, the, power, of, any, jesus, blood], [have, make, us, free], [but, the, battle, still, remain], [We, contend, not, with, flesh, and, blood, but, with, spiritual, darkness, for, this, we, wage, war, but, not, ...   \n",
       "1  [[You, better, be, nice, you, better, think, twice, you, better, be, careful, You, better, be, nice, you, better, think, twice, you, better, be, careful, be, you, dream, I, can, see, it, in, -PRON-, eye], [something, tell, me, you, be, about, to, say, goodbye], [and, I, wonder, be, you, tired, of, -PRON-, touch], [once, you, hold, me, now, it, do, not, mean, as, much, You, do, not, love, me, like, you, use, to, love, me, baby, body, soul, and, mind], [hey, hey], [hey, before, you, go, throw,...   \n",
       "\n",
       "          0         1         2         3    ...          290       291  \\\n",
       "0  0.018069  0.056996  0.053011  0.082020    ...    -0.078472  0.024860   \n",
       "1 -0.000483  0.010578  0.104912  0.130242    ...     0.019077  0.165598   \n",
       "\n",
       "        292       293       294       295       296       297       298  \\\n",
       "0 -0.092086  0.004420 -0.039378 -0.002943 -0.012103 -0.049402  0.062549   \n",
       "1 -0.149622  0.030454 -0.003322 -0.068253  0.024765 -0.087031 -0.027532   \n",
       "\n",
       "        299  \n",
       "0 -0.053977  \n",
       "1 -0.014364  \n",
       "\n",
       "[2 rows x 306 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors = []\n",
    "for doc in df.Lemmatized_sentences:\n",
    "    vectors.append(document2vec(doc, 300))\n",
    "\n",
    "#Create vector DF and concat to our original DF\n",
    "vector_df = pd.DataFrame(vectors)\n",
    "vector_df.reset_index(drop=True, inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df = pd.concat([df, vector_df], axis=1)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def score_support(clf, X_train, y_train, X_test, y_test):\n",
    "    print('train score:', clf.score(X_train, y_train))\n",
    "    print('test score:', clf.score(X_test, y_test))\n",
    "\n",
    "X = df.loc[:,~df.columns.isin(['song', 'year', 'artist', 'genre', 'lyrics', 'Lemmatized_sentences'])]\n",
    "y = df.loc[:,'genre']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score: 0.5681135681135682\n",
      "test score: 0.5393013100436681\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "svc = LinearSVC(C=1, random_state=42)\n",
    "svc.fit(X_train, y_train)\n",
    "\n",
    "score_support(svc, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score: 0.9994539994539995\n",
      "test score: 0.5584061135371179\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gbc = GradientBoostingClassifier(max_depth=6, n_estimators=500, learning_rate=.05)\n",
    "gbc.fit(X_train, y_train)\n",
    "\n",
    "score_support(gbc, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score: 0.9994539994539995\n",
      "test score: 0.4497816593886463\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn= KNeighborsClassifier(n_neighbors=10, weights='distance')\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "score_support(knn, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score: 0.5638820638820639\n",
      "test score: 0.5403930131004366\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(C=5)\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "score_support(lr, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
